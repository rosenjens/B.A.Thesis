\documentclass[11pt]{article}
\usepackage[T1]{fontenc}
\usepackage{makeidx}
\usepackage{amsmath}
\usepackage[british]{babel}

\renewcommand*\contentsname{Table of Contents}

\title{Mid-air typing for whole-hand input in three dimensions}
\author{Jens Rosén \\ Jens.Rosen.3447@student.uu.se}
\date{\today}

\begin{document}


\maketitle
\thispagestyle{empty}

\pagebreak
\tableofcontents
\thispagestyle{empty}
\pagebreak

%proprioception

\section{Introduction}
\setcounter{page}{1}
The keyboard plays a significant role in the human-computer interaction (HCI). Computer users are often custom to common sets of input and output devices such as keyboard, mouse and monitor. Many modern operating systems use a window icon menu pointer (WIMP) user interface, setting a standard of how to interact with computers.%, where the keyboard and mouse are the main input devises.

%The keyboard and mouse are the main input devises when using a computer.
When it comes to typing text the main alternative is the keyboard and it has now been a part of the human-computer interaction for a very long time, where it plays a central role.\cite{20043dui} %Nevertheless, it is not always convenient to use a physical device for inputting data.
Nevertheless, it is not always the most convenient way of inputting data. Sometimes it would be rather practical to use other ways to enter text without touching a physical keyboard, where a mid-air way of entering data would be really handy. 
An application area from the everyday life would be while a person is cooking or baking and needs to look up a recipe on the computer, with grease or dough all over the hands.

The first typewriters had keyboards with keys ordered alphabetically.\cite{website:ne:tangentbord} During the 1870's the keyboard layout for typewriters started to be dominated by the qwerty, which was developed to increase typing speed, by considering the mechanic limitations of the early typewriters.\cite{website:ne:tangentbord} Since then the qwerty layout has been the standard and was later adapted to the computer keyboard. Some attempts has been to change the layout (e.g. Dvorak) but none has really taken the place of qwerty.

The aim of this report is to propose a method for horizontal text input based on the qwerty keyboard layout for the Leap Motion Controller. A camera-based device that tracks your fingers and hands using infra red light.
One interesting aspect of the problem is if the feedback that is provided to the user is sufficient and if the Leap Motion Controller can provide adequate data for this task. 

The questions to be answered in this thesis are: 
\begin{itemize}
  \item Would it be possible to create a qwerty layout keyboard with the Leap Motion Controller?
  \item Can this keyboard provide sufficient writing speed?
\end{itemize}

\pagebreak

\subsection{Project Background}
The material for this thesis comes from the company Spree AB, referred to as Spree. A problem that occurs when using the Leap Motion Controller is how to enter text without turning to a keyboard. Spree were curious if the Leap Motion Controller could be used as a keyboard and if using it as a keyboard would be sensible. As a result, there would be a need for only one input device.%One problem they came across when using the Leap Motion Controller was how to enter text when using the device without turning to the keyboard. They were curious if it could work as a keyboard, and if the idea of a keyboard would make sense.

Spree's main objective is to find out in what extent the Leap Motion Controller can produce text input. They would like to get a deeper understanding in how the hands are recognized by the Leap Motion Controller and how it could be used to determine if a key is pressed or not.

\subsection{Limitations of project}
This thesis does not aim to implement other keyboard types than the Swedish qwerty layout, nor does it tend to make a comparison between different keyboard types. That is, not aiming to determine if there is a better keyboard layout than a horizontal qwerty for the Leap Motion Controller or compare it with other suggested layouts. 

%It would be possible for algorithms to auto correct text that has been written. But implementing or analyzing different auto-correcting techniques are outside the scope of this thesis. The study will only focus on the program to work on one operating system and will not take in to consideration that it should work on all Leap Motion Controller supported platforms.
Data validation is a technique that is widely used for text input especially on smartphones, where spelling mistakes are corrected directly. Implementing or analyzing different algorithms for auto-correction are outside the scope of this thesis. The study will focus on one operating system when implementing the program and will not take in to consideration that it should work on all Leap Motion Controller supported platforms.

\subsection{Disposition}
This thesis is written for a reader that has at least a basic knowledge in mathematics and computer science at Bachelor level.

Section \ref{theback} goes through a theoretical background in the field of three dimensional input. It aims to give the reader a foundation to the topic of this thesis. The main focus for this section concerns hand-to-computer interaction, but also introduces the reader to a more general idea of three dimensional input. Furthermore some relevant concepts in the field are explained, and related work to this thesis are discussed.

The thesis then continues in Section \ref{projover} with a description of the project itself. The first part concerns a more details description of the Leap Motion Controller and the Application Programming Interface used with the device. The section end with a general idea for the implementation for a virtual qwerty keyboard.

In Section \ref{impl} the implementation of the project is presented to the reader. This section contains information on how a keystroke is detected, the layout of the keyboard and how feedback is presented to the user. 

Then the project is tested and evaluated in Section \ref{testev}. In this section the proposed keyboard is examined and the result from a test is discussed. The thesis ends with a conclusion and the questions asked in introduction are answered.

%\pagebreak
\section{Theoretical Background}\label{theback}
This section aims to give a foundation to the field of three dimensional interaction. Focus mainly lies on interaction where the hand is used as input, but a general idea of three dimensional input is as well presented to the reader.

\subsection{Human-Computer Interaction in three dimensional space}
%Human-Computer Interaction (HCI) defines the communication between a user and a computer system. Humans and computers do not speak the same language and therefor they need a way be able to communicate with each other. The interface in between is acting like an interpreter uniting the two. 
Human-Computer Interaction defines the communication between a user and a computer system. Humans and computers do not communicate in the same way and therefor they need a way to be able to speak to each other. The interface in between is acting like an interpreter uniting the two.

%It has now for several decades been the standard that the interaction with computers mostly has been through the use of a mouse and keyboard\cite{05489218}. 

When it comes to giving instructions to the computer, it has now for several decades been the standard that the interaction is done through the use of mouse and keyboard\cite{05489218}. They are designed for two dimensional input and work well with standard window icon menu pointer user interfaces, but for three dimensional input they are less suitable\cite{20043dui}. 
%They are well suited for the window icon menu pointer system, but for humans to interact and navigate with a three dimensional environment, a mouse and keyboard can be hard to use\cite{20043dui}. 
A more appropriate way would be to use a three dimensional user interface. That is a interface that allows the users to directly perform the interaction in three dimensional space, this could be done by using e.g. direct hand motions.
	
Research on three dimensional interaction began in the 1960's\cite{20043dui}. Even if the research in this area began more than a half century ago the keyboard and mouse still has a strong position\cite{?}. Hand motion, mentioned above, is one way of doing three dimensional interaction, nonetheless there are many researched ways of interact with computers through three dimensional space. 
%Interacting through hand motions is one way for HCI, nonetheless it is not the only way of interact with computers through three dimensional space. 

\paragraph{Degrees of freedom}
One method of comparing three dimensional input devices is to compare the use of degrees of freedom. This is a measurement of the number of parameters that a system can use to acquire information\cite{ne.se-firhetsgrad}. A higher number indicates that more data is necessary to describe the state of the input. Examples of devices with low degree of freedom are the keyboard, mouse and joystick. 

Using a mouse to navigate in three dimensional space can be hard because the mouse has two degrees of freedom and to fully navigate three are needed. Therefor, having fewer degrees of freedom than the dimensions of the space makes for difficult positioning.
%With fewer degrees of freedom then the environment trying navigate in, the user will find it harder 
%The lack of degrees of freedom makes it harder to navigate in a interface with a extra dimension.

\paragraph{The human hand}
The human hand is very complex and can be used as an advanced input device that opens up for great control of the computer. It consists of 27 bones, tendons and a large amount of muscles that allow for great flexibility\cite{ne.se/hand}. %Nationalencyklopedin, hand. http://www.ne.se/uppslagsverk/encyklopedi/lång/hand

If the hand is able to move freely, it allows for a total of 29 degrees of freedom\cite{Sturman1992}. The fingers constitute 23 of the total amount and the additional six are due to rotation and translation of the hand. However, a large value does not necessary mean that the full potential needs to be used. A simpler task could take the orientation of the hand in to account, making use of only three degrees of freedom.

%When the palm is able to move freely, the whole hand has 29 degrees of freedom\cite{Sturman1992}.
%If the palm is able to move freely in space, there are in the whole hand 29 degrees of freedom.\cite{Sturman1992} 
%That is 23 degrees of freedom in the fingers and the extra six degrees of freedom due to the rotation and translation of the hand.

%Gestures are another way to use the hands for HCI. %Using gestures in HCI could be an more natural way of communicating with 

\paragraph{Gestures and naturalness}
Zhou Ren et al.\cite{rhgrwks} believes that hand gestures are a more natural way for humans to communicate with computers. In the way that gestures resemble more the way humans interact with each other. They use the term of a ``natural user interface'' in their paper. Others like Donald A. Norman claims, in his text \textit{Natural User Interfaces Are Not Natural}\cite{p6-norman}, that most gestures are not natural and nor are they easy to memorize, which is a negative consequence of gestures. But Norman is not all opposed towards gestures and think that they eventually will find their place in Human-computer interaction. 

%The thought of naturalness is that hand movements and gestures would be more natural to the human mind. 
%The thought of naturalness is that there are some methods that are more natural to the human mind, like hand gestures.
Naturalness is the idea that there are some communication methods are more natural to the human mind, like gestures compared to a joystick. It is aspiring to be a intuitive way of interacting with computers. Instead of having to learn how to interact with a computer, naturalness refer to a natural way of doing things, what first comes to our minds, and a way of direct control with unobstructed peripheral.

%some of the factors that must be taken into consideration when choosing an input devise to use with a three dimensional user interface, is the ergonomics and the type of tasks that will be performed. 
According to Doug A. Bowman et al.\cite{20043dui} ergonomics and the type of task are two key factors that must be taken into consideration when choosing an input device for a three dimensional user interface. Ergonomics is an important consideration when it comes to user experience. The device should not expose the user for difficult situations where the user can get injured or feel uncomfortable. This could lead to that the user chooses not to carry out a certain task because of poor design.
%The ergonomics is an important consideration. A user should not have to be exposed to difficult situations in which the body can be injured or where the user chooses not to carry out a certain task because of poor design.

\subsection{Three dimensional input techniques}
%There are various techniques that can be used for communicating with a computer through three dimensions. Different devices can be beneficial for various tasks. %%Lägg till något om att här kommer tre tekniker....
There are various techniques and devices that can be used for communicating with a computer. Like for two dimensional input devices, different techniques have different benefits and drawbacks depending on the task. In the following section three techniques for three dimensional input will be presented, camera-based, glove-based and accelerometer-based input.

\paragraph{Camera-based input}
%Camera-based systems use a camera image to determine positions in three dimensional space. One way to detect the position of objects is to use markers, either LED lights or coloured spots. For example, markers of different colour can be attached to the fingers tips and the device can then distinguish between the fingers more easily. 
Camera-based system uses, like the name suggest, a camera image to retrieve the input from its surroundings. Object positions can for example be tracked by using markers like coloured dots or lights. 
When different coloured markers are attached to each finger tip it makes it easier to distinguish between them in the image.

Not all camera-based systems use markers, there is also the marker free approach. This makes it harder for the device to see specific objects, but gives the user a system that needs less preparation. The biggest advantage is that the user is not obstructed by accessories when using the device. A disadvantage on the other hand for all type of camera-based input is that line of site is needed to determine good positioning.

%Then there is the marker free approach, where there are no fixed points in the image to look for. This gives the user a system that can be used straight away without any preparation, and the user is not obstructed by peripheral. A disadvantage when using a camera-based input device is that line of site is needed to determine good positioning.

Microsoft Kinect uses marker free camera tracking. This system uses an infra red laser and an infrared camera to measure depth, and an additional colour camera\cite{06290794}. The two cameras work together to make a three dimensional image of the environment in front of it. The resolution on the Kinect is quite small, around 640 $\times$ 480 typically\cite{06470686}, this is an disadvantage when trying to track smaller object, e.g fingers at a distance. %giving it an disadvantage when trying to track smaller objects like fingers at distance. 
Kinect is better at tracking bigger body parts.

The Leap Motion Controller, that is used in this thesis, is also a camera based device that uses three infra red lights and two infra red cameras to capture images of the hands. More about the Leap Motion Controller in section \ref{leap}.

\paragraph{Glove-based input}
Gloves cover the hand and can be used to track the position and motion of the hand. Using glove-based input is not new, for several decades researchers have been using this approach to track hand motion\cite{Sturman1992}, and over the many different kind of glove-based devices have been developed.
%Using gloves to tracking the hands has been researched for several decades now\cite{Sturman1992}. 
%Many kinds of glove-based devices have been developed for tracking hands. 


%For example, has gloves have been used, with good result, for tracking sign languages.\cite{out}

Glove-based input can give a high precision in positioning and they are not as much affected by its surroundings as a camera system. Background noise or the lighting in the room do not hinder the glove from tracking an accurate position. This usually makes gloves a more reliable system to use\cite{06470686}. Reading sign language is an area were using this kind of system gives good result\cite{out}.
%One usage for hand tracking is to read sign language, in this case gloves can be used with a good result .

On the downside, when using a glove-based system the glove itself can interfere with the user from performing natural gestures. Wearing a glove makes the user not as free as a camera-based system, of course depending on the design of the glove.

%Gloves, with a high precision in positioning, can ensure a more reliable system compared to camera-based systems where the use of cameras can be of disadvantage.\cite{06470686} 
%Another advantage is that it is not effected by the surrounding, background noise or the lighting in the room do not hinder the glove from pointing out an accurate position. The negative side of using a glove is that the glove it self can interfere with the user from performing more natural gestures. Wearing a glove make the user not as free as a camera-based system, of course depending on the design of the glove.

David J. Sturman writes about several gloves in his article \textit{A survey of glove-based input}\cite{sturmanASoG}. One of the earliest gloves was Sayre Glove that was developed in the 1977, which uses a lightweight glove based on light passing through tubes along the fingers. When a finger is being bend less light passes through, and by measuring the light it is possible to determine how much the finger has bent.

%An early glove was the Sayre Glove that was developed in the 1977, which is a lightweight glove based on light passing through tubes along the fingers. When the fingers is being bend less light passes through, and measuring the light can determine how much the finger is being bent.

\paragraph{Accelerometer-based input}
An accelerometer measures an objects acceleration\cite{ne.se}, similar to the glove-based systems, accelerometer-based systems are something that needs to be worn on the body. 
%Nationalencyklopedin, accelerometer. http://www.ne.se/uppslagsverk/encyklopedi/lång/accelerometer
Using accelerometers it is then possible to measure the speed and direction of an object.
%Accelerometers measure the changes in speed and direction, and can there by determine how objects are moving. 
A product that uses accelerometer for human-computer interaction is the Nintendo Wii remote\cite{out}.

\subsection{Application area}
There are many areas that could benefit from three dimensional input, especially where there is a need for more complex input methods. 
One example that David Joel Sturman\cite{Sturman1992} mention is the use of manually controlled robots in unfriendly environments where humans should not go.
%David Joel Sturman\cite{Sturman1992} brings up an example of unfriendly environments. There manually controlled robots could be used instead of humans.
%David Joel Sturman\cite{Sturman1992} brings up the example of unfriendly environments were manual controlled robots could be used. 
In highly radioactive areas or deep down in the sea where it is dangerous and expensive to send humans, advanced robots could instead be sent. If these robots are to be more or less manually controlled, and at the same time be able to carry out complex tasks it will require multiple parameters to be managed. Using joysticks, switches and buttons for this kind of task lets the user only control a few degrees of freedom at a time. Instead a three dimensional interface can be used with the hand as input, allowing for more degrees of freedom.

Camera-based systems lets the user use mid-air interaction, where communication with the computer is performed with out physical touching the input devices. This kind of interaction can improve areas where the user would not want to touch a surface e.g. for hygienic reasons.
%Mid-air interaction can also improve areas of where the user would not want to touch a surface for hygienic reasons. 
Cash machines are places that people touch often and therefor are perfect locations for bacteria and disease to transmit between people\cite{?}.
%Cash machine, is one example where many people touch the same surface with their hands and is a perfect place for bacteria and disease to transmit between people. 
The use of mid-air interaction would prevent direct contact with any infected area and still be sufficient to use.

%Computer games is another area that could benefit a lot from making users feel more physically interactive and involved in the game.  
Computer games could use three dimensional input to make users feel more physically interactive and involved in the game, but also benefit from more degrees of freedom. Particularly virtual worlds could be an interesting application area.

%A three dimensional keyboard could be used together with other three dimensional applications where the user has to enter text. Instead of having the user change between a physical keyboard and other devices when entering text, the user would be able to use one device for all the computer interaction. 
Sometimes it is required that the user to enters text. When using mid-air interaction, a three dimensional interface keyboard could be used together with other three dimensional applications where the user has to enter text. Instead of having the user change between a physical keyboard and other devices when entering text, the user would be able to use one device for all the computer interaction. 

This kind of keyboard would also be rather practical within the health care. A dentist could use a way to input medical data while working with a patient, and would be able to easily turn back and forth between the patient and the computer without sterilizing the hands. 

%An obvious use of three dimensional input is for computer animation and modeling of the body. 

\subsection{Challenges with three dimensional input}

%Three dimensional interaction can be difficult. The following subsection will present five areas of challenges associated with three dimensional input.

%Three dimensional interaction is difficult and there are many challenges associated with three dimensional input. The keyboard and mouse are the two most common input devices and have been used in human-computer interaction for several decades. They are reliable tools in the interaction with computers. 
	
%A first challenge to figure out is whether an application would benefit from a three dimensional input at all. Not all applications can make use of more dimensions. To just apply three dimensional input on any system that today uses keyboard or mouse would be waste of resources. %Maybe it just means that the current system is cumbersome and must be reinvented to easier handle the human body as input.

%Challenging for all type of input is the need for reliable responsiveness. A system needs to be quick and responsive, and particularly in a system where you use body motions as input. When using a three dimensional input device, delay can have an big impact on the result and greatly affect the accuracy.\cite{p36-herndon}

Three dimensional interaction can be difficult. Not all applications can make use of extra dimensions and to just apply three dimensional input to any system that today uses keyboard or mouse would be a waste of resources.

General for all types of human-computer interaction is the need of reliable responsiveness. A input system needs to be quick and responsive, and this is particularly true with a system that uses body motion as input. Delay, when using three dimensional interaction, can have an considerable negative effect on the outcome\cite{p36-herndon}.

In the following subsection five additional areas of challenge associated with three dimensional input will be presented. 


\paragraph{The device}
Different devices are suitable for different tasks. 
%A glove-based device can be more uncomfortable to use than to use a motion tracking with a camera, but the trade-off could be more reliable data. For example a camera device can have the problem of seeing all the fingers at all times. A object that is not in the line of sight of the camera will be problematic to use as input, e.g. one finger can intersects another and be hidden from view.
A camera-based system is more comfortable to use than a glove-base system due to the absence of a glove, but the trade-off can be the accuracy in the data. The problem with a camera device is that it needs a line of sight to objects it is tracking. For example a camera can have problem seeing all fingers at all times, one finger can intersect another and be hidden from view. 
Huan Du et al.\cite{paper} suggests that a solution to this particular problem for camera devices would be the use of a more complicated model and that lost or hidden information should be approximated.

\paragraph{Ergonomics}
%The comfort and the effects a system has on the human body is an important factor to consider. Using a three dimensional input device, where the user need to interact by holding their arms in the mid-air, require more active muscles than interacting with a conventional mouse and keyboard.\cite{p2473-ni} 
%When this interaction occurs for a longer time it can be experienced discomfortable and can have negative effects on the human body. 
%It is not natural to hold the hands up high for a longer time and can have negative effects on the human body. 
%This can be discomfortable during longer use. 
%Movements and gestures that require high precision can also be inconvenient to use, especially when this movements are to be done over longer period of time.\cite{p28-baudel}
How a system feels and the physical effect it has on the body are two important factors to consider. 
Systems like the Leap Motion Controller, that require the user to hold there hands in mid-air, will lead to the user having more active muscles than interacting with a conventional mouse and keyboard\cite{p2473-ni}.
When using this kind of systems over longer times it can be experienced as discomfortable, especially movements and gestures that require high precision\cite{p28-baudel}.

%When designing a user interface it is important to have the ergonomics in mind and think of the human needs and circumstances. Many repetitive motions in a user interface can be discomfort and cause injuries and should be avoided.\cite{Sturman1992} 
Ergonomics should be a significant part when designing and implementing a user interface. 
If a system is poorly designed the user will be reluctant to use it, and probably use something else.
With to many repetitive motions can be unpleasant and might even injure the user\cite{Sturman1992}.

\paragraph{Degrees of freedom}
%Thus, the hand is very complex, it can also be a disadvantage when used as input. 
%
%All the joints and movability in the hand makes it hard to track. 
%
%There are as much as 23 degrees of freedom just in the fingers. 
%
%However, when using the hand as input source it does not mean that the full potential of degrees of freedom needs to be used. 
%
%A simpler task would be to use the orientation of the hand in space as input, making use of only three degrees of freedom. 
The human body is flexible and can move in many different ways, this resolves in a lot of degrees of freedom. 
As mentioned in section 2.1, due to the anatomy, two hands allow for more than 50 degrees of freedom. 
%Just the hands allow for great mobility and many degrees of freedom this is due to its anatomy.
%Just considering the hands, that through its anatomy of bones can create complexed movement patterns, allows for great mobility and many degrees of freedom. 
But a high number of degrees of freedom can be challenging to take advantage of and does not necessary correspond to the best choice in every task.
The use of more degrees of freedom than the task requires can even be confusing for the user\cite{p36-herndon}. %The use of higher degrees of freedom for tasks with lower degrees of freedom can be confusing.\cite{p36-herndon} 

%Some tasks may require some sort of reduction in degrees of freedom to be helpful to the user.\cite{Sturman1992}
For some tasks it may be essential to reduce the degree of freedom to be useful\cite{Sturman1992}. 
Hence, managing a window icon menu pointer user interface does not benefit from using all degrees of freedom that the hand can provide. In this sense mouse and keyboard are a much better choice, due to the few degrees of freedom.%, that are design with at most two degrees of freedom. 

The precision of pointing is reduced when using a device with more degrees of freedom than needed\cite{p2473-ni}.
%The precision of pointing is lower when using a device with more degrees of freedom than needed.\cite{p2473-ni} 
%When pointing in a three dimensional user interface the precision is lower  when using a mouse in the same situation.\cite{p2473-ni} 
%This is due to the problem of using to many degrees of freedom and the problem of keeping the body still.
It is hard to keep the hand completely still. %when not resting on another fixed object. 
When intending to moving a finger just one direction, it is hard not to move in more than one axis. 
This makes it difficult to use the hand for more precise movements in a two dimensional environment where the mouse already is a satisfying pointing device.
%which makes it hard to use the hand for more precise movements that the mouse otherwise can do.

%Problems can also occur when using a device that have less degrees of freedom than needed for the task that the user wants to perform\cite{p36-herndon}.
Problems can also occur when there are less degrees of freedom than needed for the task that the user wants to perform\cite{p36-herndon}. 
It can for example be hard to interact in an three dimensional environment with a input device with only two degrees of freedom. 
%This leads to more complicated interaction than it would have been with a device with three degrees of freedom, that directly can interact in three dimensional space.
This leads to a more complicated interaction than if the device had extra degrees of freedom and could therefore more directly interact in three dimensional space.

\paragraph{Feedback}
Feedback could be divided into three categories: visual feedback, tactile and kinesthetic feedback, and auditory feedback. This corresponds to the three types of responses a computer is able to produce when communicating with a human.
%This correspond to the three types of information that the communication with a computer is capable of producing to a human.

Humans use forces, like friction and gravity, to simplify interaction with objects\cite{p36-herndon}. With just the hands as information source the human body has the possibility to experience structure even in the smallest things\cite{website:ne:hand}. When interacting with virtual objects the physical response is reduced and the interaction made much harder. It is therefore important to give the user other suitable types of feedback to be able to perform the task at hand.
%It is important to give the user suitable feedback for the task at hand. 

When using a physical keyboard the user gets all three categories of feedback. 
Visually feedback at the same time as the user sees what is written. 
Tactile and kinesthetic feedback through the fingers when feeling the keys on the keyboard, and last auditory feedback, from hearing the sound the key press makes. %when pressing a key it makes a sound. 
All this feedback helps the user when writing on a keyboard, and makes it more effective to use. 
%When using just a camera-based system for input its hard or impossible do give any tactile feedback. 
For a camera-based system it is very hard or even impossible to give any tactile feedback.
%Then the feedback that can be given to a user is limited to visual and auditory feedback.
The feedback for this kind of system is limited to visual and auditory feedback. Genetically humans are made to respond to visual movement and sound by looking towards the moving object or the source of the sound\cite{p36-herndon}. 

Visual and auditory feedback can not replace tactile feedback. Touching or seizing hold of virtual objects that are in the mid-air can be a very challenging task without any tactile feedback. Nevertheless, different tasks require different feedback for a good result. 
%For a mid-air keyboard the question is whatever it is possible to develop a keyboard with the feedback that can be provided. 
%For a mid-air keyboard it is important to 

\paragraph{Naturalness}
Three dimensional input would give the user a feeling of being more in direct control over the computer. With one small movement of the hand the user is able to control the whole computer. This would be a more natural approach than using a intermediate device, like the mouse, but this kind of system should be natural for everyone.
%A problem that then arises is when the system need to be natural for everyone.

Differences in culture, age and education could mean that people in one group think that one approach is obvious, but it is not clear for another group. An example of a misunderstanding that could occur is that nodding the head means yes for some people and no for others.

When dealing with gestures, another problem is to determine between an active action and when a movement is not intended to be a gesture. The user could perform a random action that should not be recognized as a gesture to the system.

\subsection{Text input methods for tree dimensional user interfaces}
There are several methods that can be used to write text on a computer, and the area of text input is much researched\cite{chp3A10}. Different kinds of approaches to text input have different benefits depending on how they are used. All devices have different specifications that determine what method will work best. One effective way of typing on one device can be very ineffective on another.  

A physical keyboard can be used without looking at the keys. A skilled typist can use just the tactile and kinesthetic feedback to produce the wanted text. Nevertheless, when using a mobile phone with a touch keyboard, or other devices with a touch screen, visual attentiveness is needed. There are however applications that try to reduce the visual need on mobile touch screens. One example is Fleksy\footnote{http://www.fleksy.com \cite{web:fleksy}}, that is as a qwerty keyboard that uses an advanced prediction engine, with the benefiting of increased typing speed. 

Three dimensional space invites to take advantage of the extra degrees of freedom the it permits. 
%To just adapt conventional ways of typing is maybe not the way to go. 
To simply adapt conventional ways of typing without reflecting is not the way to go.
%Text input in three dimensional space can perhaps benefit from a more effective approach. 
Text input in three dimensional space can benefit from a more effective approach. 
%One method of typing that could be better is gesture-based technique. 
One method of typing that tries a different perspective is the gesture-based technique. 
TiltType\cite{tilttype} and GesText\cite{p2173-jones} are two devices that use accelerometers to write text with gestures. GesText could during tests produce words at a rate of 5,4 words per minute (WPM). 
%On a conventional keyboard a skilled professional typist can produce speeds up to 120 WPM, and a two-finger typist writes at a speed around 20-30 WPM.\cite{ayres2005120}
On a conventional keyboard a skilled typist can produce speeds up to 120 WPM, and a two-finger typist \footnote{a typer that only uses two fingers when writing} writes at a speed around 20-30 WPM\cite{ayres2005120}.

To ease the step for learning how to use three dimensional human-computer interaction, one way is to make text input similar to typing on a physical keyboard. It would make it easier for users if they recognize how to type. 
%Nevertheless, three dimensional user interfaces adds another spectrum to typing and traditional typing that is based on techniques from keyboard, mouse or pointer may not be suitable to adapt.
Nevertheless, three dimensional user interfaces adds another spectrum to typing. 
Traditional typing techniques that are based on using keyboard, mouse may not be suitable to adapt.

%One method, that is close related to keyboard input, is the pointing or selection-based techniques where the user select letters by pointing on the symbol they want to select. 
An alternative method is to use a pointing or selection-based technique. In this case the user select the letters by pointing on the wanted symbol. This method is closely related to the keyboard input. 
Different keyboard layouts can also be used for the comfort of the user.
The straight forward approach is to arrange the letter in a two dimensional plain in a qwerty order. But letters can also be arrange in a more advanced order that uses the potential of three dimensions better.

Tests have though shown that the use of letters on a flat surface gives a better performance compared to symbols ordered in a cube in three dimensions\cite{chp3A10}. This may be the result of users being more familiar to the more conventional layout than the new cube approach. Another aspect is that when moving the hand freely in space the precision of pointing is lower\cite{p2473-ni}.

A different method is to let the user write the letters in mid-air like writing on a piece of paper or a blackboard. Alexander Schick et al.\cite{sp202-schick} propose a system for handwriting recognition that they can use with an accuracy of 86\%. It uses cameras to track the users hands and does not rely on markers or other sensors to be attached on the hands. Users did complain about the low typing speed but no value for words per minute was mentioned.

Yang Liu et al.\cite{01578696} proposes a text input system for wearable computers were the user writes a letter with the fingertip. They suggest that a normal keyboard is not convenient for wearable computers and test the Graffiti 2 alphabet with a promising result.

%Another paper that proposes a way for text entry is written by Tayfur Coskun et al.\cite{coskun2012APCHGestyboard}, where the user should use all ten fingers for text input. 
In the paper by Tayfur Coskun et al.\cite{coskun2012APCHGestyboard} they suggest another way for text entry, where the user useses all ten fingers as input. 
%The method is based on the qwerty layout but instead of mapping a keyboard, gestures for individual finger are used. 
Their method is based on the qwerty layout, but instead of pressing on specific keys gestures for individual finger are used. 
By tapping and then sliding the finger in different ways different letters and symbols are generated. 
The idea is to use this approach on multi-touch devices but would maybe be suitable even for mid-air typing as well. 

\subsection{Related work}  \label{rel}
%This section aims to do a survey of previous work in the field of text entry in three dimensional space. 
%There are several papers on the subject of typing in mid-air. 
%The approach to text entry in three dimensional space come across as different depending on what device is used to interact with the computer. 
%This field deals with an interesting problem that has been addressed by many researchers.  
%Some of the papers use devices that are commercial e.g. Microsoft Kinect and their SDK. 

%There are several papers on the subject of mid-air typing. 
%\textit{Mid-air text entry methods}\cite{barbanik.2014dipl} a thesis from 2014 studied five different approaches to mid-air typing using Microsoft Kinect and their SDK. Barbariuskiy
%First a vertical keyboard with qwerty layout that uses Microsofts integrated push function to press a key. 
%Then a circular keyboard, where the user selects a letter by rotating a pointer to the right position with one hand and selecting it with a gesture. 
%Two of the methods are based on the same idea, where the user select from three sets of letters, like T9, and then pattern matching to words. 
%The last approach is with developing an 8pen system.

%There are several papers on the subject of mid-air typing. 
Large wall displays are one area where mid-air keyboard would be beneficial. Garth Shoemaker et al.\cite{p231-shoemake} wrote a paper presented in 2009 about text input techniques for large displays where they compare three methods: circle, qwerty, and a cube keyboard, which use a hand held device. Their result was the the qwerty keyboard was faster at producing words, a rate of 18,9 words per minute, and had fewer errors. They drew the conclusion that a qwerty keyboard would be good way of doing text input on larger screens.  

%Another paper the deals with the problem of typing on large displays is \textit{Selection-based mid-air text entry on large displays}\cite{chp3A10} from 2013.
Another paper that addresses the subject of typing on large displays is \textit{Selection-based mid-air text entry on large displays}\cite{chp3A10} from 2013. 
Anders Markussen et al. propose three different input methods to compare: H4 Mid-air, based on a method for game control text input; MultiTap, based on how the phone is used for typing with nine keys; and a projected qwerty keyboard, a keyboard projected on the screen. 
H4 Mid-air and MultiTap are designed so they can be used without visual feedback. 
%They found that the most successful method was the projected qwerty keyboard with an average writing speed of 13,2 words per minute. 
Anders Markussen et al. found that the most successful method was the projected qwerty keyboard with an average writing speed of 13,2 words per minute. 

Taichi Murase et al.\cite{p9-murase} propose in their paper \textit{Gesture keyboard requiring only one camera} from 2011 a virtual qwerty keyboard using a camera to detect key presses. 
%Keys are correlated with fingers and one finger corresponds to more the one key. 
Each keyboard key can only be pressed by a gesture from a specific finger. For example a forward and pressing gesture of the left ringfinger corresponds to a 'o'. Due to this, the keyboard is not fixed and the user has the option to change hand position during typing. They do not mention the average typing speed for their experiment but the input error rate is 8.6\%.
%The keyboard tries to determine depth to determine which key was pressed.

For the Leap Motion Controller there are a few applications that can be used for typing. One is the DexType\footnote{http://www.dextype.com \cite{web:dextype}}, where the letters are ordered into a single line on the bottom of the screen. Typing is done by using the fingers as pointers on the screen and writing is like playing a piano.

ASETNIOP\footnote{http://www.asetniop.com \cite{web:asetniop}} is a chord keyboard that can be used with the Leap Motion Controller. The fingers represent different keys and to produce characters the user presses different combinations of theses keys. It is similar to playing a chord on a piano. With just a few keys it is possible to produce all the keyboard characters. An advantage for this type of keyboard is that the placement of the fingers in mid-air does not matter. A disadvantage on the other hand is that the user has to learn a new way to type.

%\pagebreak
\section{Project Overview}\label{projover}
This section contains a proposal to a horizontal keyboard based on the qwerty keyboard layout for the Leap Motion Controller. 

\subsection{The Leap Motion Controller} \label{leap}
The Leap Motion Controller is a small USB device that detects and tracks hands, fingers, and pointing tools, e.g. a pencil.
%To use the device no sensors or markers on the hands are needed.
It uses marker and sensor free hand detection, so it can be used with out any set up.
The device consists of three infra red LED lights, the light reflects of objects above the device and is captured by two infrared cameras. 
%It produces monochrome images that are analyzed to detect hands, fingers, and tools.
From this two monochrome are produced that are analyzed to detect hands, fingers, and tools.

Objects in the visual field of the Leap Motion Controller can be seen in the range of 25 to 600 millimeters above it. It uses the two cameras to detect depth and a three dimensional view. The field of vision that the Leap Motion Controller can see can be described as a cone like view with its tip pointing at the device. 
%The area that it can see can be describe as cone like view with its tip pointing at the device.

A right-handed Cartesian coordinate system is use to determine positions, where the origin is placed at the center of the device itself. 
The x-axis is running parallel with the longer side of the device and moving an object to the right of the device will increase the x-value. The z-axis goes perpendicular to the x-axis in the horizontal plane and the z-value is decreased by moving the hand forward. Both the x- and z-value can be negative, but the z-value can only be positive. The y-axis is vertical to the Leap Motion Controller where the zero point is on top of the device. 

%For the Leap Motion Controller to detect hands, fingers and tools they must be visible for the controller to recognize them and to be able to give objects a accurate position in space. 
The Leap Motion Controller needs to have a line of sight to a object to be able to tracking it. Otherwise, it can not recognize hands, fingers, and other tools and therefor not give these objects a accurate position in space.
%This could be an issue when it is important to get input from all fingers all the time. 
This is an issue when it comes to always knowing where the fingers are.
When fingers move close to each other or are hidden from view, they disappear from the system. 
%This could lead to that a hand does not always have five fingers and it is possible for a hand object to have just one or no fingers at all.
If this happens the system sees a hand with fewer than five fingers, and it is even possible for the hand to have just one finger or no fingers at all.

The Leap Motion Controller can also track gestures, like swiping movements or a finger drawing a circle. The measurements the system uses is: microseconds for time; millimeters for distance; millimeters per second for speed; and angles are measured in radians.

\subsection{Application Programming Interface overview}
The Leap Motion Controller and its software does the image processing, and through the API it is possible to get information about hands, fingers and tools that the device has recognized. 
Leap Motion supports several programming languages, C++, C\# and Unity, Objective-C, Java, Python, and JavaScript. This thesis focuses on the Objective-C API.

The Leap Motion Controller provides data through the API as sequences of frames. 
%A frame is a representation of what the device has observed at a specific moment and contains data of what has has been tracked. 
A frame is a representation of what the device has observed at a specific moment.
To get the latest frame it is possible to ask the API for it, but It is also possible to let the system proved information when a new frame is available.
%To get a frame it is possible to ask for the latest frame or the system can provide information that there is a new frame. 

A frame object consists of lists of the observed fingers, hands, tools, pointables, and gestures. 
%When a developer is in no need to distinguish between tools and fingers it is possible to use a pointables list, that includes all finger and tool objects in that frame.
The pointable list contains all finger and tool objects in that frame. This list is useful when there is not need to distinguish between object that can point. 
Hand objects represents a hand detected in the Leap Motion Controllers field of view. 
%The hand object consists of information e.g. palm position, palm velocity, rotation, direction, a set of fingers, and tools held by the hand. 
Each hand object consists of several parameters, e.g. palm position, palm velocity, rotation, direction, a set of fingers, and tools held by the hand. 

A pointable is a finger or tool, and has variables like length, position of the tip, and velocity of the tip. Both fingers and tools are classified as pointable objects, but it is possible to determine which is which through the functions \texttt{isHand} or \texttt{isTool}.

When a gesture is recognized by the Leap Motion Controller, the system adds the recognized gesture to the current frame. For gestures that occur during several frames the gesture will continue to exist in the gesture list with updated values. Other gestures that only occur during one frame will only exist in that frames gesture list. 

It is also possible to use an interactionBox, that is a rectangular cuboid that is inside the Leaps field of view and provides normalized coordinates relating to the cuboid. 
%This could be beneficial when mapping coordinates to drawing on a screen.
This makes it easier to transfer Leap Motion Controller coordinates to screen coordinates.

\subsection{The virtual qwerty keyboard}
%Basically, typing is a movement and rotation of the hand to a specific target, where the movement involves the whole-hand and all its fingers.\cite{1264.full} 
Typing is a sequence of keystrokes. It is basically hitting specific targets in a specific order to produce text. This involves both displacement and rotation of the wholes-hand and all its fingers\cite{1264.full}.
Each individual keystroke can be seen as a movement to a target that can be modeled by Fitts's law\cite{p91-zhai}.
The movement can be divided into tree steps: moving to the key; pressing the key; and returning to the originated position\cite{1264.full}. 

%To have a completely fixed keyboard in mid-air could be problematic because while holding the arms and hands in mid-air they tend to drift.\cite{chp3A10}
Keeping the hands stationary in mid-air is tricky, while not resting arms or wrists on any support they tend to drift\cite{chp3A10}. This can be problematic when designing a fixed mid-air keyboard.
%Holding ones hands static in the air for a longer time can also be painful for shoulders and arms and be bad for the user. 
It is also not ideal, and even unpleasant for the users have their hands static for longer periods, it may lead to pain in shoulders and arms.
Consequently, having a stationary keyboard is a bad idea and could mean that the users is either too far away or pressing more keys than intended. 
%A solution where measuring the speed of the fingers lets the user choose at what hight to write and be allowed to drift horizontally with the hands and still be able to type.
A solution is to check for key presses by individual fingers. In this thesis this is done by measuring the speed of the fingers, letting the user choose at what hight to write and it allows for horizontal drift.

The small size of the Leap Motion Controller makes it easy to carry around. Connected to a device with a tiny keyboard or with a small touch screen, a virtual keyboard would allow the user to enjoy the comfort of a full sized keyboard.

\paragraph{Layout}
Most who use a keyboard today use it with a qwerty layout and are therefore acquainted with that style of writing\cite{p91-zhai}. The keyboard for this thesis is based on the qwerty layout, so users can take advantage of their learned way of typing. 
In section \ref{rel} Related work the thesis of Barbariyskiy\cite{barbanik.2014dipl} is cited, suggesting that qwerty is a good layout to use. The design will try to mimic a physical keyboard as much as possible.

This thesis does not however aim to determine if there is a better keyboard layout for the Leap Motion Controller or compare it with other suggested layouts. The qwerty layout may not be the most suitable for typing with the Leap Motion Controller but its wide spread makes it a good starting point when researching keyboards for three dimensional interaction. One better way of typing could be the a chord keyboard suggested in \cite{00017378}.

One possible explanation for that the qwerty layout gets better result in tests is that the learning curve is less steep.
When using the qwerty layout most users will not have a extensive learning curve. 
With that in mind, an alphabetical ordered keyboard would also work, but using a layout the user is comfortable with and knows without thinking about it is a better way to go. 
A user that is not so comfortable with the qwerty layout will not be able to benefit from that layout being implemented with a virtual keyboard and would therefore be better of with another design. 

\paragraph{Feedback}
One problem with a virtual keyboard is the feedback to the user, not everyone is used to typing without looking at the keyboard. 
To make it easier for the user and have a better chance of people using the keyboard, the aim should be to minimize the cognitive load\cite{p91-zhai}.

Without feeling (or seeing) the key under the fingers the user has to imagine a keyboard floating around in the air. 
Writing or even moving the hands in the mid-air lacks tactile and kinesthetic feedback. 
This is a big issue because writing on a keyboard depends so much on feeling the keys. 
Using a physical keyboard it normally requires a good tactile feedback. % to the user.%[?]
%When typing in the mid-air there is a lack of tactical feedback and the user has to rely on other feedback that is provided, like visual and sound. 
Now, when typing the user has to rely on other feedback, like visual and sound. 

%\pagebreak
\section{Implementation} \label{impl}
The keyboard was implemented using the Leap Motion SDK in Objective-C on a MacBook Pro with OS X. The detection of hands, fingers and tools is all done by the Leap Motion software. There is no way of getting the raw image data and doing the calculations yourself. 

The keyboard is implemented with using only the english letters, the spacebar and backspace. Because the modifier keys has been subtracted the user can only produce lower case letters.

%%
\subsection{A Keystroke}
For each \texttt{LeapFrame} there is a list of pointables that the Leap Motion Controller has acknowledged. When the device finds a finger, it does not track all the joints in the fingers and therefore it is not possible to take advantage of the hands full potential regarding degrees of freedom. 
For the keyboard in this thesis, the idea is that both fingers and tools could be used as input and consequently be able to make a key press. 
In the implementation, the \texttt{LeapPointable} class is used. 

%The idea is that the user should be able to type on the keyboard at any hight in the range of the Leap Motion Controller.
The user should be able to type on the keyboard at any hight in the range of the Leap Motion Controller
There should not be a certain virtual surface to touch, like a horizontal plane 200 millimeter above the device. 
The keystrokes are instead detected using the vertical velocity. 
Every pointable tip is monitored and if it exceeds a certain velocity it is considered a key press. 
This is done with the \texttt{tipVelocity} method in the \texttt{LeapPointable} class. 

When typing on a keyboard it is most likely that only one key is pressed at a time. 
Nevertheless moving one finger in mid-air, due to the physical characteristics of the hand, makes other fingers move at the same time. 
To make up for this, only the fastest moving finger or tool is selected as the one doing the key press. 
In \cite{1596.full} they found that in the moment of the key press, in a typical case, the velocity of the fingers does not depend on the average rate of typing. 

\[
\begin{array}{ccc}
p_{max} &=& \max \big\{ x \mid x  \in P \wedge v(x) \geq t \big\}
\end{array}
\]

The pointable $p_{max}$ is selected from the set $P$ of pointables with threshold $t$ and velocity function $v(x)$. If no pointable exceed the threshold the variable is set to \texttt{nil}.

Measuring the velocity of the tip has the benefit that different ways of typing can be used. 
%E.g. both writing with whole hand movements, in a drumming way, and writing with just finger movements will be detected by the application.
E.g. the application can be used with both whole hand movements, in a drumming way, or more commonly with just finger movements.

When the threshold is exceeded the position of the finger or tool tip is registered and further movement of the finger or tool does not effect the keystrokes position in space. 
This will make it more accurate to the position that the user receives as visual feedback. 
A finger gesture will not move in a straight vertical line towards the key during a keystroke. 
If the key press occurs at the end of the key press motion, the starting point of the movement could be above another key than the pressed key. This would have an negative effect in how the keyboard performs and is perceived by the user.

This approach is some what of a naive solution where fast movements of the hand can be interpreted as keystrokes even if the intention was not to type anything. 

During a key press no other key can be pressed. The key is released when the pointable velocity drops below a lower threshold. A second key press motion could begin before the first has ended\cite{1596.full}. This would make the positioning not as accurate as if the key press was registered in the key press gestures beginning.

To determine if and what key was pressed the pressed coordinates are compared to the key objects in the \texttt{Keyboard} class. 
%A keyboard object consists of keys, the keys them self have their position and size.
A keyboard object consists of keys, each key consists of their position and size.
If the coordinates of the keystroke are placed inside a key's boundaries the key is defined as pressed. 
%If a key is found, the system sends a keyboard event to the operating system and if not, nothing happens.
If a key is being pressed, the system sends a keyboard event to the operating system and if not, nothing happens. 

\subsection{The keyboard} \label{leapKeyboard}
The keyboard consists of the letters in the english alphabet ordered in the qwerty layout as well as two keys to help with writing, spacebar and backspace. To make it as close as possible to writing on a physical keyboard the size of the full virtual keyboard tries to adapt the size of a normal laptop keyboard. 

A key consist of six variables: the position in the horizontal plane; two size variables, height and width; the \texttt{CGKeyCode}; the string that should be label on the key; and a boolean variable telling if the key is being pressed. All the keys have the same size 19 $\times$ 19 millimeter except the spacebar and backspace that have the same hight but are 114 as well as 38 millimeters wide. 
%The padding in-between the keys is set to zero in order to help the user not to press in the margins and instead the press should resolve in a keystroke.
The padding in-between the keys is set to zero in order to remove the margins and instead each press should resolve in a keystroke.

The rows of keys are shifted to give it the characteristics of a keyboard\cite{website:ne:tangentbord} where the three rows of letters are shifted in descending order: 0, 5 and 15 millimeters. The spacebar key is place under the X- to M-key, and the backspace is moved closer to the letter keys and is placed to the right of the P-key. 

Adjustments can be done to the window size to fit the needs of the user. It can be made really small and take almost no space on the screen and can also be extended to the full width of the screen. 
It is always placed on top of the desktop to be able to, at all times, give the user the visual feedback. 
A improvement would be to have the opportunity to make it transparent so the user can work on documents behind the visualization of the keyboard.

Because it is a virtual keyboard other layouts and adjustments can be done to fit the users preferences, e.g. Dvorak can be used or any other custom set.

\subsection{Feedback}
Typing in mid-air can be hard and the user has to rely on visual and auditory feedback. 
One intension for this keyboard is to give the user sufficient feedback. 
This should help to increase the performance when writing with the Leap Motion Controller. 

Visual feedback of the xz-plane is provided to the user via the computer screen, where keys and pointables are displayed.
When the Leap Motion Controller updates the \texttt{LeapFrame}, the visual output, through a custom \texttt{NSView}, is also updated. 
All tip positions of the LeapPointable objects in the pointable list are displayed as rectangles using their x and z coordinates. 
As described in the previous section \ref{leapKeyboard} The Keyboard, when the user types a letter it triggers a keyboard event to the operating system. 
At the same time the visual key being pressed changes colour to indicate interaction. 
Both the keyboard event and changed colour helps the user understand what has happen.

The auditory feedback is given when a user performs a keystroke. 
At the same time as a key press occurs the system plays a clicking sound to indicate the keystroke. 
This sound helps the user to understand that the velocity of the key press is sufficient to exceed the threshold. 
If the user does not hit a key the sound is not played. 
So the absence of visual and auditory feedback should indicate that no key press has occurred. 

The absence of tactile feedback can play an important role for the development of a horizontal qwerty keyboard. 
Without the tactile feedback the user lacks one important component when interacting with the computer. 
%To play a more significant role the visualization of the fingers are displayed on the screen.
Trying to deal with this, the visualization of the fingers has gotten a more significant role than when using a regular keyboard.
This having the benefit that the user does not have to look down on the keyboard to be able to see the keys. 
%The user can keep the eyes more stable and less flickering for the user that has to look at the keys while typing.
The user's focus can therefore be keep on the screen and be less distracting for user that has to look at the keys while typing.

%\pagebreak
\section{Testing and Evaluation}\label{testev}
First tries shows that it is possible to use the virtual keyboard for typing. 
Overall, the functionality is that of a physical keyboard.

The speed of an input device is an important aspect for the usability, especially when it comes to producing text. 
A user does not want to use a slow system where it takes forever to type simple content.
%In this section the proposed keyboard is examined where the typing speed is measured using words per minute (WPM):
In this section the proposed keyboard is examined with typing speed measured in words per minute (WPM):
\[
\begin{array}{ccc}
\text{WPM} &=& \frac{\left\lvert{S}\right\vert }{t} \times 60 \times \frac{1}{5}
\end{array}
\]

WPM is defined using the length of the set of characters written by the user, $\left\lvert{S}\right\vert$, where the time $t$ is measured in seconds. 
The length of a word is normalized to be five characters long.

There are two types of errors that can occur when typing: corrected errors and uncorrected errors. 
Correcting an error effects the typing speed in a negative manner. 
%The user has to take the time to do a set of key presses that does not effect the length of the character set, $\left\lvert{S}\right\vert$. 
If a character is typed by mistake, the user has to take the time to replace it without effecting the length of the character set, $\left\lvert{S}\right\vert$. 
Both error types can have a negative effecting on the rhythm of typing, where the user loses focus\cite{1264.full}.
In this test the subjects was asked to correct their mistakes. 

Due to limitations of the keyboard, the test is based on only writing lower case words and without special letters. 
The subjects in the test were native Swedish speakers so the test phrases were in Swedish using words without å, ä and ö.
WPM is used as a measure to see if the keyboard can be used at a sufficient rate.
%As shown in Table 1 the average result for using the keyboard was 14,6 WPM and a top result of 17,8 WPM.
As shown in Table 1 the average result for using the keyboard was 14,6 WPM, with a top result of 17,8 WPM.

\begin{table}[htdp]
\caption{Test result}
\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
Method & High & Low & Average \\ 
\hline
Fingers & 16,9 & 11,7 & 14,3 \\
Tools & 17,8 & 12,5 & 14.9 \\
\hline
\hline
Total & 17,8 & 11,7 & 14,6 \\
\hline
\end{tabular}
\end{center}
\label{default}
\end{table}

%The statistical result shows a quite low WPM compared to writing on a physical keyboard and could be an indication that a virtual mid-air qwerty keyboard is not the right way to go regarding mid-air typing.
The statistical result shows a quite low WPM compared to writing on a physical keyboard.
This could be an indication that a virtual mid-air qwerty keyboard is not the most optimal solution regarding mid-air typing.
%Concerning the performance rate of the keyboard, there may be a better ways of typing in the mid-air when using a device made for gestures.
Concerning the performance rate of the keyboard, there may be better ways of typing when using a device made for gestures, such as the Leap Motion Controller.
This way is slow and makes it less likely that one would want to write long texts using this method, but it could be used for shorter text like usernames or similar.

%It is difficult to write two letters that lies next to each other on the keyboard. 
%Typing, e.g. R and E with two different fingers on each key prove to be difficult. 
During the test, it has shown to be difficult to write two letters that lies next to each other and that are typed with the same hand, e.g. E and R, a common occurring letter bigram. 
%The different lengths of the fingers makes it harder to aim two keys at the same time and it is also because the Leap Motion Controller sometimes has problems detecting all the fingers when they move close to each other. 
%When typing on this virtual keyboard the user needs to have the fingers more straight than using a physical keyboard.
When typing on the virtual keyboard the user needs to have more straight fingers than using a physical keyboard. 
Different lengths on fingers makes it harder to aim at two keys at the same time and to enter them after each other. 
The Leap Motion Controller sometimes also has the problem of detecting all the fingers when they move close to each other. 
This could lead to the user using more of a hunt and peck technique, a technique where the user only uses one finger on each hand to type. 
The test result does not take in consideration on what typing technique the subject used.

%Similar to two-fingered typing, the use of tools the motion becomes more of a drumming way of typing. 
Similar to two-fingered typing, when using tools as pointables, the motion becomes more of a drumming way of typing. 
%Tools could be used with one in each hand or with only one tool.
As seen in the result, this method of writing produces a slightly better result.

%Sometimes the Leap Motion system has problems when objects enters its field of view, making the keyboard perform keystrokes when it is not intended. 
On some occasions, when objects enters the Leap Motion Controller's field of view, the system makes the keyboard perform keystrokes when it is not intended.
This could be solved by disabling a hand or tool from performing key presses for the first seconds when it is recognized. 
Another way would be to let the user indicate when the system can write. 

A keyboard can not always be present on the screen, it would be a waste of screen space. 
%and if it is active, other applications would trigger not intended keystrokes.
If the keyboard is to be active all the time, other applications would trigger not intended keystrokes.
%One solutions would be that with a gesture the keyboard would start, and with another gesture close the keyboard.
One solutions would be to let a gesture start the keyboard, and have another gesture close the keyboard.

%\pagebreak
\section{Conclusion}
%Can a horizontal keyboard provide sufficient writing speed?
%Would it be possible to create a qwerty layout keyboard with the Leap Motion Controller?

%The aim for this thesis is to propose a horizontal qwerty keyboard for the Leap Motion Controller. 
%Writing on a keyboard requires precise hand and finger movements.
%Using the Leap Motion Controller, this thesis shows that it is possible to develop a mid-air keyboard under its premises. 
 
%A goal was explore if sufficient data would be available when using a design that mimics a physical keyboard. 
%The implementation is designed to mimic how a physical keyboard is used. 
%One intent was to explore if sufficient data would be available for this task, using a design that mimics how a physical keyboard is used. 
%The conclusion is that it is possible to develop a mid-air keyboard for the Leap Motion Controller with these premises. 

Writing on a keyboard requires precise hand and finger movements. 
The result shows that it is possible to create a mid-air qwerty layout keyboard using the Leap Motion Controller. 
An advantage when using the Leap Motion Controller is that it can be used out of the box and it does not require any hardware or other markers on the hands to be used.
This also goes for the keyboard itself that can be used straight away. 
A disadvantage is that it is a camera-based system and therefore it can loose sight of fingers or confuse two fingers for one.
Background lighting can also be an issue and have a negative effect on the performance.
%Two disadvantages are that the background lighting can have a negative effect on the performance of the device and that the cameras see from only one angle, making it possible to block fingers out of view.
%Another advantage is that no hardware or markers are needed on the hands to interact with the device. 
%A disadvantage is that the Leap Motion Controller uses a camera-based system and can therefore loose sight of fingers or confuse two fingers for one. 
However, it is found that the Leap Motion Controller still can supply sufficient data to mimic the use of a physical keyboard.

Using this approach, the typing speed is not the fastest and can definitely not compare to writing on a physical keyboard. 
%But, the result is good enough result for shorter inputs, e.g. a username.
%But this kind of keyboard may not be the most suitable for three dimensional interaction, or at least not for the Leap Motion Controller. 
If the typing speed is essential, this kind of keyboard may not be the most suitable using three dimensional interaction, or at least not for the Leap Motion Controller. 
%This thesis does not aim to find the best way of typing and just because keyboards work for text entry does not mean that it is the best way to enter text. 
%If the task is just to enter data in an effective way, e.g. writing long texts in a notepad kind of way, this keyboard is not beneficial with its low writing speed of approximately 15 WPM. 
For simpler tasks, e.g. signing in using a username and password or filling in an address, the typing speed is of less importance. 
Usually, the accuracy of the input is more important than the speed. 
The similarity to a physical keyboard can even be an advantage for new users. 
One can learn to use it much faster than if introduced to a completely new way of typing. 

%This is a big drawback for this kind of approach, but the similarity to a physical keyboard makes it easier for users to adapt to. 
%One can learn to use it much faster than if introduced to a completely new way of typing. 

When using a word processor or similar to write longer texts, the low typing speed of 15 WPM is not as enjoyable to use. 
Writing this paragraph would take more than six minutes.
The lack of tactile feedback for the mid-air keyboard is also a disadvantage. A negative consequence of this is a decrease in typing speed. 
The best an application area for this kind of keyboard would therefore be for shorter inputs that does not require a fast typing speed to be satisfactory.

%To imitate a physical keyboard in mid-air one disadvantage is that it lacks an important aspect of tactile feedback, and a negative consequence for this is a slower typing speed. 
%An application area for this kind of keyboard would be for shorter inputs that does not require a fast typing speed to be satisfactory.

Compared to the methods for text entry using Microsoft Kinect in \cite{barbanik.2014dipl} the proposed Leap Motion keyboard performs quite well regarding to writing speed, where the fastest of the methods performing around 4 WPM. 
Garth Shoemaker et al.\cite{p231-shoemake} concludes that a writing speed around 18,9 WPM for there qwerty keyboard is sufficient to writing by hand, therefore the top typing speed for this project at 17,8 WPM would be almost in the same region.

%An advantage when using the Leap Motion Controller is that no training is needed to calibrate the system, it can be run out of the box. 
%This also goes for the keyboard itself that can be used straight away. 
%Another advantage is that no hardware or markers are needed on the hands to interact with the device. 
%Two disadvantages are that the background lighting can have a negative effect on the performance of the device and that the cameras see from only one angle, making it possible to block fingers out of view.

The keyboard is not a natural way of communicating for humans, it is a learnt way to interact with computers. 
%So when it comes to the naturalness there could be improvements on that area, where the communication is not on the term of the computer.
When it comes to naturalness there could be improvements. 
A more natural way that could be used, or at least a method that feels more natural to the user, is speech. 

Although the virtual qwerty keyboard is not the best way for text input, a method for typing is necessary in the progress to develop a gesture based interface.

%%An improvement of the system could be play different sounds depending on if a key was hit successfully or not.

\pagebreak
\bibliographystyle{unsrt}
\bibliography{thesis}



\end{document}


